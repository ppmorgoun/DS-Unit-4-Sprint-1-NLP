{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                    raw_description  \\\n0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n2           2  b'<div><p>As a Data Scientist you will be work...   \n3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n\n                          title  \n0               Data scientist   \n1              Data Scientist I  \n2  Data Scientist - Entry Level  \n3                Data Scientist  \n4                Data Scientist  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>raw_description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "##### Your Code Here #####\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "df.rename(columns={'description': 'raw_description'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                    raw_description  \\\n0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n2           2  b'<div><p>As a Data Scientist you will be work...   \n3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n\n                          title  \\\n0               Data scientist    \n1              Data Scientist I   \n2  Data Scientist - Entry Level   \n3                Data Scientist   \n4                Data Scientist   \n\n                                 cleaned_description  \n0  Job RequirementsnConceptual understanding in M...  \n1  Job DescriptionnnAs a Data Scientist 1 you wil...  \n2  As a Data Scientist you will be working on con...  \n3  4969  6756 a monthContractUnder the general su...  \n4  Location USA xe2x80x93 multiple locationsn2 ye...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>raw_description</th>\n      <th>title</th>\n      <th>cleaned_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n      <td>Job RequirementsnConceptual understanding in M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n      <td>Job DescriptionnnAs a Data Scientist 1 you wil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n      <td>As a Data Scientist you will be working on con...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n      <td>4969  6756 a monthContractUnder the general su...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n      <td>Location USA xe2x80x93 multiple locationsn2 ye...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the text from the soup object into a new column\n",
    "### COME BACK TO THIS IF I HAVE TIME AND CLEAN BETTER\n",
    "\n",
    "def extract_text(col):\n",
    "    soup = BeautifulSoup(col, 'html.parser')\n",
    "    soup = re.sub('[^a-zA-Z 0-9]', '', soup.get_text()[1:])\n",
    "    soup = re.sub('xe2x80x99', '\\'', soup)\n",
    "    return soup\n",
    "\n",
    "df['cleaned_description'] = df['raw_description'].apply(extract_text)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job DescriptionnnAs a Data Scientist 1 you will help us build machine learning models data pipelines and microservices to help our clients navigate their healthcare journey You will do so by empowering and improving the next generation of Accolade Applications and user experiencesnA day in the lifexe2x80xa6nWork with a small agile team to design and develop mobile applications in an iterative fashionnWork with a tightknit group of development team members in SeattlenContribute to best practices and help guide the future of our applicationsnOperates effectively as a collaborative member of the development teamnOperates effectively as an individual for quick turnaround of enhancements and fixesnResponsible for meeting expectations and deliverables on time with high qualitynDrive and implement new features within our mobile applicationsnPerform thorough manual testing and writing test cases that cover all areasnIdentify new development toolsapproaches that will increase code quality efficiency and best practicesnDevelop and champion the the development processes coding style guidelines and architectural designs necessary to innovate and maintain great product qualitynEffectively turns design documents and graphics into performant usable UInDemonstrates creative technical and analytical skillsnDemonstrates ability to communicate effectively in both technical and business environmentsnnQualificationsnnWhat we are looking forxe2x80xa6nMasterxe2x80x99s Degree in Computer Science Math or related fieldnComputer Science fundamentals as illustrated through algorithm design problem solving and complexity analysisnMust have 1 year realworld experience developing and deploying microservices or data pipelinesnMust have a fundamental understanding of key machine learning concepts such as accuracy measures crossvalidation and open source machine learning librariesnFluent in Python and SQLnProficient with writing unitfunctional tests and familiar with automation frameworksnExperience with cloud infrastructure such as AWS or Azure is a plusnExperience with distributed data pipelines such as a Spark is a plusnStrong written and oral communication skillsnDesire and willingness to work in an Agile collaborative innovative flexible and teamoriented environmentnHandson detailoriented methodical  inquisitivenA motivated selfstarter with a solid level of experience that quickly grasps complex challengesnA skillful communicator with experience working with technical management teamsn A service oriented person who thinks Customer FirstnFast fail entrepreneurial spiritnThrives in a fastpaced environment where continuous improvement is the norm and the bar for quality is extremely highnExcited by the challenges of working in a product team undergoing rapid international growthnAdditional InformationnnWhat is important to usnCreating an enduring company that is hyperfocused on our culture and making a meaningful impact in the lives of our employees members and customers The secret to our success isnWe find joy and purpose in serving othersnMaking a difference in our membersxe2x80x99 and customersxe2x80x99 lives is what we do Even when itxe2x80x99s hard we do the right thing for the right reasonsnWe are strong individually and together wexe2x80x99re powerfulnTrusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways having fun along the waynWe roll up our sleeves and get stuff donenResults motivate us And we arent afraid of the hard work or tough decisions needed to get us therenWexe2x80x99re boldly and relentlessly reinventing healthcarenWere curious and act big  not afraid to knock down barriers or take calculated risks to change the world one person at a timenAll your information will be kept confidential according to EEO guidelines\n"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "\n",
    "soup = BeautifulSoup(df['raw_description'][1], 'html.parser')\n",
    "soup = re.sub('[^a-zA-Z 0-9]', '', soup.get_text()[1:])\n",
    "print(soup)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                    raw_description  \\\n0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n2           2  b'<div><p>As a Data Scientist you will be work...   \n3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n\n                          title  \\\n0               Data scientist    \n1              Data Scientist I   \n2  Data Scientist - Entry Level   \n3                Data Scientist   \n4                Data Scientist   \n\n                                 cleaned_description  \\\n0  Job RequirementsnConceptual understanding in M...   \n1  Job DescriptionnnAs a Data Scientist 1 you wil...   \n2  As a Data Scientist you will be working on con...   \n3  4969  6756 a monthContractUnder the general su...   \n4  Location USA xe2x80x93 multiple locationsn2 ye...   \n\n                                              tokens  \n0  [job, requirementsnconceptual, understand, mac...  \n1  [job, descriptionnnas, data, scientist, 1, hel...  \n2  [data, scientist, work, consult, business, res...  \n3  [4969,  , 6756, monthcontractunder, general, s...  \n4  [location, usa, xe2x80x93, multiple, locations...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>raw_description</th>\n      <th>title</th>\n      <th>cleaned_description</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n      <td>Job RequirementsnConceptual understanding in M...</td>\n      <td>[job, requirementsnconceptual, understand, mac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n      <td>Job DescriptionnnAs a Data Scientist 1 you wil...</td>\n      <td>[job, descriptionnnas, data, scientist, 1, hel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n      <td>As a Data Scientist you will be working on con...</td>\n      <td>[data, scientist, work, consult, business, res...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n      <td>4969  6756 a monthContractUnder the general su...</td>\n      <td>[4969,  , 6756, monthcontractunder, general, s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n      <td>Location USA xe2x80x93 multiple locationsn2 ye...</td>\n      <td>[location, usa, xe2x80x93, multiple, locations...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Create a list of tokens using nlp and the sample string \"text\"\n",
    "    tokens = []\n",
    "\n",
    "    # iterate through the tokens in the doc\n",
    "    for token in doc:\n",
    "\n",
    "        # create a couple of filters for low quality tokens\n",
    "        if (token.is_stop != True) and (token.is_punct != True):\n",
    "            # save case normalized lemmas to token list\n",
    "            tokens.append(token.lemma_.lower())\n",
    "\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['cleaned_description'].apply(tokenizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 5956)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     ability    able    analytics    business    datum    deep    design  \\\n0          0       0            0           0        0       0         0   \n1          0       0            0           0        0       0         0   \n2          0       0            0           0        0       0         0   \n3          0       0            0           0        0       0         0   \n4          0       0            0           0        0       0         0   \n\n     disability    disability      engineer  ...  year relate  \\\n0             0               0           0  ...            0   \n1             0               0           0  ...            0   \n2             0               0           0  ...            0   \n3             0               0           0  ...            0   \n4             0               0           0  ...            0   \n\n   year relate experience  year relevant  year relevant work  year work  \\\n0                       0              0                   0          0   \n1                       0              0                   0          0   \n2                       0              0                   0          0   \n3                       0              0                   0          0   \n4                       0              0                   0          0   \n\n   year work experience  yes  york  york city  younnabout  \n0                     0    0     0          0           0  \n1                     0    0     0          0           0  \n2                     0    0     0          0           0  \n3                     0    0     0          0           0  \n4                     0    0     0          0           0  \n\n[5 rows x 5956 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ability</th>\n      <th>able</th>\n      <th>analytics</th>\n      <th>business</th>\n      <th>datum</th>\n      <th>deep</th>\n      <th>design</th>\n      <th>disability</th>\n      <th>disability</th>\n      <th>engineer</th>\n      <th>...</th>\n      <th>year relate</th>\n      <th>year relate experience</th>\n      <th>year relevant</th>\n      <th>year relevant work</th>\n      <th>year work</th>\n      <th>year work experience</th>\n      <th>yes</th>\n      <th>york</th>\n      <th>york city</th>\n      <th>younnabout</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 5956 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "##### Your Code Here #####\n",
    "\n",
    "# instantiate a countvector object\n",
    "vect = CountVectorizer(stop_words='english',\n",
    "                       ngram_range=(1,3),\n",
    "                       min_df=5,\n",
    "                       max_df = 0.25,\n",
    "                       tokenizer = tokenizer)\n",
    "\n",
    "# Learn our vocab\n",
    "vect.fit(df['cleaned_description'])\n",
    "\n",
    "# Get sparce DTM\n",
    "dtm = vect.transform(df['cleaned_description'])\n",
    "\n",
    "dtm = pd.DataFrame(data=dtm.todense(), columns= vect.get_feature_names())\n",
    "print(dtm.shape)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "client          238\ndigital         199\nstate           190\nemployee        178\njob             162\nglobal          159\nuser            158\nintelligence    157\nperform         149\nnetwork         149\nlevel           146\nlike            146\nprotect         145\nprogram         144\ninternal        142\ndiverse         140\ngrowth          139\napproach        139\nstakeholder     136\nquality         136\ndtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "# Most common words\n",
    "dtm.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Data scientist\\xa0', 'Data Scientist I',\n       'Data Scientist - Entry Level', 'Data Scientist',\n       'Associate Data Scientist – Premium Analytics',\n       'Sr. Data Scientist', 'Data Scientist, Lifecyle',\n       'Data Scientist, Neuroimaging', 'Data Scientist II',\n       'Data Scientist - Risk', 'Data Analyst/Jr. Data Scientist',\n       'Assistant Data Scientist', 'Data Scientist, Junior',\n       'Data Scientist – Personalization', 'Data Scientist - [Remote]',\n       'Measurement Data Scientist', 'WTE Data Science Engineer',\n       'Data Scientist, Sales', 'Data Scientist Intern',\n       'Jr. Data Scientist', 'Sr. Data Engineer',\n       'Data Scientist/Data Analytics Intern - Summer 2019',\n       'Data Science Internship – Summer 2019',\n       'Data Scientist Summer Intern', 'Data Scientist (Senior)',\n       'Data Scientist Internship - Summer 2019',\n       'Data Scientist - Insurance', 'Junior Data Scientist',\n       'Data Scientist - Computer Vision',\n       'Data Scientist Summer Internship 2019',\n       'Data Scientist (Multiple levels)', 'Senior Data Scientist',\n       'Data Scientist – Intern (Summer 2019)',\n       'Data Scientist - Forecasting and Anomaly Detection Platform',\n       'Data Scientist Summer Internship',\n       'Data Scientist (2019 Summer Intern)', 'Data Scientist 2',\n       'Data Scientist - Machine Learning',\n       'Data Scientist - Machine Learning, AdTech',\n       'Data Scientist, Engineering',\n       'Junior Data Scientist - Big Data (Entry-Level)',\n       '2019 University Graduate - Data Scientist - Policy Economics',\n       'Undergraduate Internship/Co-op Program - Data Scientist',\n       'Data Scientist : 19-01367', 'Data Scientist-CA-',\n       'Clinical Data Scientist', 'Data Scientist Internship',\n       'Data Scientist (GEC11901)', 'Data Scientist (PYTHON, HADOOP)',\n       'Staff Data Scientist - NLP',\n       '2019 University Graduate - Data Scientist - Core Product',\n       'Principal Data Scientist', 'Senior Data Scientist- Atlanta, GA',\n       'Data Scientist, Product',\n       'Associate Data Scientist - Associate Statistical Modeler',\n       'A &A Division /Data Scientist',\n       'Customer Facing Data Scientist - Telecom',\n       'Applied Data Scientist', 'Data Scientist (Labs)',\n       'Data Scientist- Corporate',\n       'Sponsor Funded Professional | Data Scientist',\n       'E-09-311 Data Scientist', 'Associate Data Scientist',\n       'Artificial Intelligence (AI) Data Scientist',\n       '2019 PhD University Graduate - Data Scientist I/II - Intelligent Insights',\n       'People Data Scientist',\n       'Data Scientist/Quantitative Analyst, Engineering', 'Data Analyst',\n       'Junior Data Scientist(s)- MI and AI', 'Staff Data Scientist',\n       'Data Scientist Intern - Summer 2019',\n       'Graduate Studies Program - Data Scientist',\n       'Data Scientist, Redtech', 'Investigative Data Scientist',\n       'Data Scientist, Alexa Shopping NLU',\n       'Data Scientist/Visualization Master',\n       'Staff Data Scientist, Vudu', 'Data Scientist - Top Secret',\n       'REMOTE Data Scientist Opening',\n       'Applied Data Scientist, Government',\n       'Senior Data Scientist - Modeling',\n       'Data Scientist-Global People Analytics',\n       'Data Scientist - Washington DC', 'Data Scientist | Rider Growth',\n       'Intern, Data Engineer', 'Intern, Data Science',\n       '2019 Canon Insights Summer Internship - Data Science',\n       \"Data Scientist - Master's Entry Level Consultant - Atlanta\",\n       'Data Scientist- Zillow Offers', 'Data Science Internships',\n       'Sr Data Scientist', 'Data Science Intern',\n       'Geospatial Data Scientist', 'People Analytics Data Scientist',\n       'Data Scientist - COR Administration', 'Data Engineer',\n       'Senior Business Intelligence Data Engineer',\n       'Data Analytics Consultant', 'Behavioral Data Scientist',\n       'Data Scientist - SEA',\n       'Sr Data Scientist, NLP - Customer Obsession',\n       'Data Scientist (Forecasting)',\n       'Associate Data Scientist Internship - Customer Data & Analytics',\n       'Data Scientist, Advanced Marketing Analytics',\n       'Data Scientist - Oil and Gas', 'DATA SCIENTIST',\n       'Data Scientist (Machine Learning)',\n       'Data Scientist, Operations Data Science',\n       'Data Scientist Intern/Coop', 'Data Scientist, Sourcing Analytics',\n       'Senior Data Scientist (GEC11902)', 'CCS Data Scientist',\n       'Data Scientist | Rider Experience', 'Data Scientist - AVP',\n       'Data Science Engineer', 'Data Scientist, AR/VR',\n       'Senior Data Scientist, Trading Technologies',\n       'Principal Data Scientist - Telecommute',\n       'Data Scientist - Optimize',\n       '2019 University Graduate - Data Scientist - Marketplace',\n       'Data Scientist | Shared Rides',\n       'Data Scientist I - Agent Based Modeler (Java/Python)',\n       'Software Engineer/Data Scientist', 'Data Scientist (HCE)',\n       'Data Scientist Jr.', 'Data Scientist, Infrastructure',\n       'IBM Marketing PhD Data Scientist Intern, Summer 2019',\n       'Marketing Data Scientist',\n       'Senior Data Scientist - Analytics (f/m/d)',\n       'Security Data Scientist',\n       'Data Scientist, AMP Analytics & Data Products',\n       'Data Scientist, Clients', 'Data Analyst / Data Scientist',\n       'DATA SCIENTIST/ 40 HOURS/ DAYS/ BWH SLEEP MEDICINE',\n       'Intern, Data Scientist Cloud Platform', 'Analyst, Data Scientist',\n       'Data Scientist, Analytics',\n       'Data Scientist / Applied Mathematician',\n       'Senior Data Scientist (TS/SCI)',\n       'Data Scientist/Researcher (~25% profit sharing annually)',\n       '2019 PhD University Graduate - Data Scientist I/II - Applied Behavioral Science',\n       'Data Scientist- Machine Translation',\n       'Statistical Data Scientist', 'Data Scientist - Merch Scenarios',\n       'Product Data Scientist',\n       '2019 PhD University Graduate - Data Scientist I/II - Experimentation',\n       'Metagenomics Data Scientist (Scientist I/II)',\n       'Data Scientist (Outward, Inc.)', 'Data Scientist I-III',\n       'Manufacturing Data Scientist',\n       'Clinical Pharmacology Data Scientist',\n       'Sr. Data Scientist, Advanced Analytics',\n       'Data Scientist - Predictive Analytics',\n       'Data Scientist (Multiple Levels)',\n       'Sr. Data Scientist – Data for Insights Practice',\n       'Senior Data Scientist, Customer Experience',\n       'Data Scientist - Styling Algorithms',\n       'Data Scientist, Insights - CU108',\n       'Students Seeking Data Scientist Full Time Employment',\n       'Data Scientist, Seller', 'Data Scientist (Intern)',\n       'Data Scientist, Meta', 'Data Scientist, Pricing',\n       'Advisor: CCO Audience Strategy - Data Science',\n       'Senior Data Scientist, Machine Learning',\n       'Data Scientist (Subject Matter Expert)', 'Modeler/Data Scientist',\n       'Data Scientist, Analytics - Messenger Relevance',\n       'Lead Data Scientist', 'Data Scientist, Supply Chain Innovation',\n       'Data Scientist – Content Marketing Acquisition',\n       'Marketing Data Science Intern - Summer 2019',\n       'Data Analyst / Jr. Data Scientist',\n       'Data Scientist- Enterprise Product Analytics',\n       'Data Scientist - Delphi', 'Senior Data Science Engineer',\n       '2019 PhD Data Scientist Internship - Forecasting and Anomaly Detection Platform'],\n      dtype=object)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 5956)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     ability    able    analytics    business    datum    deep    design  \\\n0        0.0     0.0          0.0         0.0      0.0     0.0       0.0   \n1        0.0     0.0          0.0         0.0      0.0     0.0       0.0   \n2        0.0     0.0          0.0         0.0      0.0     0.0       0.0   \n3        0.0     0.0          0.0         0.0      0.0     0.0       0.0   \n4        0.0     0.0          0.0         0.0      0.0     0.0       0.0   \n\n     disability    disability      engineer  ...  year relate  \\\n0           0.0             0.0         0.0  ...          0.0   \n1           0.0             0.0         0.0  ...          0.0   \n2           0.0             0.0         0.0  ...          0.0   \n3           0.0             0.0         0.0  ...          0.0   \n4           0.0             0.0         0.0  ...          0.0   \n\n   year relate experience  year relevant  year relevant work  year work  \\\n0                     0.0            0.0                 0.0        0.0   \n1                     0.0            0.0                 0.0        0.0   \n2                     0.0            0.0                 0.0        0.0   \n3                     0.0            0.0                 0.0        0.0   \n4                     0.0            0.0                 0.0        0.0   \n\n   year work experience  yes  york  york city  younnabout  \n0                   0.0  0.0   0.0        0.0         0.0  \n1                   0.0  0.0   0.0        0.0         0.0  \n2                   0.0  0.0   0.0        0.0         0.0  \n3                   0.0  0.0   0.0        0.0         0.0  \n4                   0.0  0.0   0.0        0.0         0.0  \n\n[5 rows x 5956 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ability</th>\n      <th>able</th>\n      <th>analytics</th>\n      <th>business</th>\n      <th>datum</th>\n      <th>deep</th>\n      <th>design</th>\n      <th>disability</th>\n      <th>disability</th>\n      <th>engineer</th>\n      <th>...</th>\n      <th>year relate</th>\n      <th>year relate experience</th>\n      <th>year relevant</th>\n      <th>year relevant work</th>\n      <th>year work</th>\n      <th>year work experience</th>\n      <th>yes</th>\n      <th>york</th>\n      <th>york city</th>\n      <th>younnabout</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 5956 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "##### Your Code Here #####\n",
    "\n",
    "# instantiate a tfidf object\n",
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                       ngram_range=(1,3),\n",
    "                       min_df=5,\n",
    "                       max_df = 0.25,\n",
    "                       tokenizer = tokenizer)\n",
    "\n",
    "# Learn our vocab\n",
    "tfidf.fit(df['cleaned_description'])\n",
    "\n",
    "# Get sparce DTM\n",
    "dtm = tfidf.transform(df['cleaned_description'])\n",
    "\n",
    "dtm = pd.DataFrame(data=dtm.todense(), columns= tfidf.get_feature_names())\n",
    "print(dtm.shape)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0      Job RequirementsnConceptual understanding in M...\n1      Job DescriptionnnAs a Data Scientist 1 you wil...\n2      As a Data Scientist you will be working on con...\n3      4969  6756 a monthContractUnder the general su...\n4      Location USA xe2x80x93 multiple locationsn2 ye...\n                             ...                        \n421    About UsnWant to be part of a fantastic and fu...\n422    InternshipAt Uber we ignite opportunity by set...\n423    200000  350000 a yearA million people a year d...\n424    SENIOR DATA SCIENTISTnJOB DESCRIPTIONnnABOUT U...\n425    Cerner Intelligence is a new innovative organi...\nName: cleaned_description, Length: 426, dtype: object"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_description']\n",
    "#ideal = \"Machine learning engineer role, client facing, excellent renumeration, travel opportinities, small team / start-up.\"\n",
    "#ideal = pd.Series([ideal])\n",
    "#ideal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm=\"kd_tree\")\n",
    "\n",
    "# Fit on DTM\n",
    "nn.fit(dtm)\n",
    "\n",
    "# writing my ideal job description and vectorizing it using our tfidf model\n",
    "ideal = \"Machine learning engineer role, client facing, excellent renumeration, travel opportinities, small team / start-up.\"\n",
    "ideal = pd.Series([ideal]) # Turning it into a series as that's what dfidf is expecting\n",
    "ideal_vectorized = tfidf.transform(ideal)\n",
    "ideal_vectorized = pd.DataFrame(data=ideal_vectorized.todense(), columns= tfidf.get_feature_names())\n",
    "# Query Using kneighbors\n",
    "neigh_dist, neigh_ind = nn.kneighbors(ideal_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.30289781, 1.32557847, 1.34004016, 1.34301779, 1.34395737]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[182, 345, 311, 178, 137]])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About ScoopnnScoop brings coworkers and neighbors together to enjoy a smooth carpooling experiencexe2x80x94unlocking new opportunities to create friendships improve their wellbeing and make the most of their valuable timennLearn more in Forbes httpswwwforbescomsitesmiguelhelft20171108with36millioninfinancingscoopwantstomakecarpoolingmainstreamnnEngineering  ScoopnnFew companies get to face such diverse technical challenges as Scoop and we've built a team of people excited to face these challenges together while investing in each others' growthnnScoop's engineering team may move bits and pixels but we also put real live human beings in cars together We're touching problems academics have written about for years and have data that no other company has ever collectednnBut Scoop knows engineering is not a lone discipline We're a small team with varied backgrounds big companies VCbacked startups bootcamps academia We like to build together and we like to learn together Our entire team and process are built around helping you grow and be successful And we'd love to tell you more about the impact you could have at ScoopnIn this role you willnCollaborate with Scoops product and engineering team to draw key insights to drive critical decision makingnPerform exploratory data analysis to gain a deeper understanding of behaviors and trendsnWork on end to end development of data products including experimentation infrastructure and performance monitoringnContribute to the development and implementation of models as well as monitoring of the models outcomes and performancenYou shouldnHave a strong understanding of statistical and machine learning conceptsnHave a degree in a quantitative field or an equivalent work experiencenHave experience with endtoend quantitative analysis from data preparation through analysis and modeling to visualizationnBe proficient in Python andor Scala Experience writing code in production environment is a plusnHave strong communication skillsnLife  ScoopnnFounded in 2015 and based in downtown SF our team mixes technology and elbow grease every day with one statistic in our crosshairs 80 of Americans drive alone to work At Scoop we envision a world where commuters feel empowered xe2x80x94 starting with a choice to make their commute a meaningful part of their day We embody that same spirit within our own culture empowering every team member to make this the most meaningful experience of their careernnWalk into Scoop and you'll find a furry tailwagging welcoming committee In many ways these fluffy faces exemplify the energy that flows through our office They are a reminder that while we're focused and driven we shouldn't take ourselves too seriously They also help bridge the gap between our homes and our workplace just like a Scoop carpoolnnThe atmosphere overall is dynamic and unique It's influenced by our backgrounds at successful startups big tech companies and premier consulting firms xe2x80x94 blended and crafted into what feels natural and right for this company It plays out in our balance of scrappy and strategic frameworks and fast thinkingnnAt Scoop we're all united by our desire to change the way people get to work xe2x80x94 and committed to enjoying the journey together along the way\n",
      "Small businesses are the backbone of the American economy providing innovation growth and job opportunities to the communities around them Many small businesses need funds to run and grow their business but often don't get the financial help they need from traditional banks That's where BlueVine comes in BlueVine is a leading provider of small business financing We're using cutting edge technology to disrupt the traditional banking industry and develop the next generation of fast and simple financial products designed for today's small businesses BlueVine is headquartered in Redwood City CA and backed by leading investors including Menlo Ventures Citi Ventures SVB Financial Nationwide Insurance M12 Microsoft's Venture ArmnnBlueVine is searching for a Junior Data Scientist who will be responsible for the critical decisionmaking processes driving our automation risk analysis credibility scoring fraud detection and financial strength prediction You work will include the application of machine learning techniques to modeling data mining and statistical analyses that push limits of performance and efficiency You will also be responsible for writing deploying and maintaining production grade Python codenWHAT YOULL DOnWork closely with data scientists on all stages of new model development data exploration feature generation and model training using the most advanced tools in the spacenSupport and optimize existing models by identifying new data sources and generating novel featuresnCollaborate with teams across the company Business Operations Marketing Finance and RisknCommunicate key results to senior management in verbal visual and written medianOwn the implementation of your models and insights and see them deliver real resultsnWHAT WE LOOK FORnBachelors Degree in Computer Science Statistics Economics Mathematics Information Systems or equivalent technical degreen12 years of handson experience as a Data Scientist Machine Learning engineer or a comparable analytical positionn12 years of handson experience with Python and the supporting analysis librariesecosystemnAn excellent understanding of both traditional statistical modeling and Machine Learning techniques and algorithms regression clustering ensembling random forest gradient boosting deep learning neural networks etcnProficiency with Python and SQLnFamiliarity with Git and LinuxOS command linenSelfstarter  excited to learn unfamiliar concepts on the jobnDeliveryoriented approachability to get things done within a strict time frameability to juggle multiple assignmentsnDeep interest in learning both the theoretical and practical aspects of working with and deriving insights from datanGreat communication skillsnNICE TO HAVEnMaster's Degree in Computer Science Statistics Economics Mathematics Information Systems or equivalentnGraduate of leading Data Science boot camp Galvanize Metis etcnSuperior Python programming skillsSuperior SQL skillsnPrevious work experience with Amazon AWS ecosystemnPrevious work experience with remote development  distributed development architecturesnBENEFITS  PERKSnReceive over 1000 annually for a wellness benefit of your choicenFree commuter benefits  CalTrain passes for SF employees and a monthly parking allowance for SFNJ employeesnWeekly catered lunchesnUnlimited snacks in fully stocked kitchensnGenerous PTO and holidaysnExcellent health coverage and life insurance benefitsnGenerous paid parental leave which covers up to 15 weeksnPetfriendly offices\n",
      "The companynnAppZen delivers the world's leading AI platform for modern finance teams Starting with business spend we automate manual process uncover problems and optimize decision making for enterprises around the globe including onefourth of the Fortune 500 Our platform combines patented deep learning computer vision and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen AppZen is a must have for CFOs and their teams to reduce spend achieve compliance and streamline processnnWe've taken off this year Since we released our platform in 2016 nearly 1000 enterprises have standardized on AppZen including three of the top ten banks four of the top ten media companies three of the top ten pharmaceutical manufacturers two of the top five aerospace companies and five of the top ten software providers We were a Gartner Cool Vendor last year have been recognized as one of the fastestgrowing technology companies in the market and we just announced 35million in Series B fundingnnWe are looking for a Data Scientist to come and work on our growing AI stack You will be working with a team of highly skilled and motivated data scientists and machine learning engineers If you are excited about natural language understanding and machine translation AppZen is the right place for you to apply and grow your skillsnRequirementsnExpertise in machine translationtransliteration translationtransliteration from multiple languages such as Chinese German Spanish andor French to English and vice versa a big plusnMS OR PHd in computer sciencenProven background in machine learning and deep learning including neural machine translation sequencetosequence models etcnHandson experience with deep learning toolkits including Tensorflow PyTorch CNTK Dynet etcnAbility to formulate a research problem design experiment and implement solutions in PythonnExperience working with standard MTNLP toolkits preferred eg Moses SRILM Marian T2T Sockeye etcnDesign and deployment of realworld largescale userfacing MT systems preferrednExcellent spoken and written communication skillsnExperience in building machine translation and natural language processing systems eg commercial speech products or government speech projectsnSolid understanding of machine learning fundamentals and familiar with standard algorithms and techniquesnScientific thinking and the ability to inventnSolid software development experiencenYou are a team playernNicetoHavenTrackrecord of having developed novel algorithms eg publications in one or more of the following KDD WWW NIPS ISWC NAACL ACL SIGIR EMNLP ICML etcnFluent verbal and written in more than 1 language\n",
      "RSG is seeking an experienced Data Scientist to join a growing team of market researchers and modelers who provide quality data insights to a range of clients This position is based in our White River Junction Vermont officennAS A DATA SCIENTISTnnYou support analytics and data science needs across RSG's markets including market research data analysis and quantitative model development for public and private sector clients in transportation and consumer goods markets ranging from small planning organizations to statewide agencies and Fortune 500 firms Your work impacts the travel and mobility landscape of numerous cities and regions by helping clients provide valuable services to their customers You confront challenging technical problems with reproducible datadriven solutions develop workflows for data processing and analysis and contribute to a growing data science knowledge base under direction of a senior data scientistnnYou have a keen intuition for data wrangling quality assurance and making sense of complicated data landscapes You are a selfmotivated team player who can synthesize and communicate problems and effective solutions and you command the technical skills necessary to contribute to these solutions You are resourceful proactive and driven to continually improve processes and evolve analytical methods in using data and analytics to support decisionmaking across a variety of domainsnnREQUIRED QUALIFICATIONSnnBachelor's degree or equivalent experience in a quantitative field such as data science mathematics statistics engineering or a similarly relevant field of studyn3 years of experience and demonstrated skill in data science or similar field using advanced analytic methods and toolsn3 years of experience with hands on data worknSolid understanding of and proficiency with Python or R and relational data in SQLnEfficient manager of workflows and processes with the ability to manage multiple competing prioritiesnProficient in technical communication data management and presentationnPREFERRED QUALIFICATIONSnnTransportation modeling experiencenMarket research experiencenData visualization experiencenFamiliarity with geolocation datanPeriodic travel is required RSG is not currently accepting H1B applicants for this position EEOAA EmployerVetsDisablednnTo ApplynnPlease visit our employment page httprsginccomjoinus\n",
      "We're Elliott Davis a rapidly growing CPA firm with over 700 professionals across multiple states within the Southeast Consistently named among the Best Places to Work we're revolutionizing what it means to specialize in the public accounting field Starting with a powerful mixture of wisdom energy and fresh perspective we dig deep finding the courage to challenge every comfortable assumption the system has been built upon Around here we may do the work of accountants but we think like startup entrepreneurs social dogooders and community leadersnSo what does that mean for you We are so glad you askednAs part of the Elliott Davis team you'll get handson experience working alongside some of the leading experts in the financial and consulting field while enjoying the freedom and autonomy to manage your career and make a positive impact on the worldnWe are looking for a Data Scientist to join our Charlotte NC team based out of our Charlotte Raleigh or Greenville office In this role you will be working with our AA practice to develop unique client deliverables This is a newly formed role and will be highly innovative to seek and develop data analytic and data visualization solutions for our current client base as well as prospective clientsnResponsibilitiesnIdentifying and addressing client needs which includes the following building strong relationships with clients identifying opportunities for and developing new firm services approaching client and innovative mindset delivering quality and value added work to clients through the power of data and analyticsnPrioritizing and handling multiple tasks researching and analyzing pertinent client industry and technical matters utilizing problemsolving skills and communicating effectively in written and verbal formats to various audiences including various levels of management at external clients in a professional business environment including those with and without a financial reporting backgroundnUnderstanding personal and team roles contributing to a positive working environment by building solid relationships with team members proactively seeking guidance clarification and feedbacknIdentifying and articulating technology solutions available in data management and manipulation big data analytics and data visualizationnPartnering with Audit and Advisory leaders to improve and optimize internal processes and develop innovative data analysis solutionsnQualificationsnMinimum of 5 years of professional experiencenAdvanced degree in Math Statistics or Computer Science or an advanced degree in Accounting or Business Administration combined with a proven track record of data analytics experiencenAbility and experience managing teams using leading programming and analytical tools to analyze data such as experience with SQL or other foundational programming language ie C Java Python etcnDemonstrated proficiency with advanced statistical tools and techniques and complex Excelbased spreadsheet functionsnExcellent verbal and written communication skills and ability to interface effectively with accounting and finance personnel ie intermediate US GAAP knowledge as well as all verticals of client managementnPreferred KnowledgeSkillsnDemonstrates extensive knowledge of and a proven record of success managing and executing data analytics projects in a realworld application Knowledge areas includenTechniques for analysis of complex big data including programming and computational techniques for large data sets and quantitative analysisnStatistical techniques for analyzing data including sampling optimization logistic regression and cluster analysis and Visualization techniques for summarizing complex data analysisnAptitude in driving efficiencies through innovative processes such as automationnDemonstrates successful leadership and entrepreneurial qualities such as taking ownership of client processes leading new initiativesprojects and effectively mentoring and training team membersnnFor immediate and confidential consideration please send your resume to annachristofariselliottdaviscom\n"
     ]
    }
   ],
   "source": [
    "neigh_ind\n",
    "\n",
    "for i in df.iloc[neigh_ind[0]]['cleaned_description']:\n",
    "    print(i)\n",
    "#df.iloc[neigh_ind[0]]['cleaned_description']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "unit_4p",
   "language": "python",
   "display_name": "Unit_4 (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}